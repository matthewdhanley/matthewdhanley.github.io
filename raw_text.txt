Hi! My name is Matthew Hanley and I am a Graduate Mechanical Engineering Student at the University of Colorado Boulder. My plans are to graduate in May of 2019 then take some time off to travel. When I return, I'd like to get to work at a job that I am passionate about. What am I passionate about? Click the different nodes to find out! 
If you don't want to play along, you can view my resume here. 
Engineering Equation Solver is a clunky piece of software that unfortunately is also very useful. I have used it in depth for thermodynamic problems, mostly in my Thermo II class when designing power cycles and assessing HVAC systems. 
"The Robot Operating System (ROS) is a set of software libraries and tools that help you build robot applications." I heavily use ROS in the robotics club. I have used it to connect sensors, microcontrollers, cameras, motors, and remote computers. With a pretty steep learning curve, ROS is a skill that I am glad to have. Nothing beats building an application to drive a robot over wifi. 
I consider myself proficient in SOLIDWORKS. I am a certified SOLIDWORKS associate and hope to take the professional exam before I leave CU. I have taken multiple classes using SOLIDWORKS. I have been the CAD engineer for almost all my projects. To me, computer aided design is an art. 
"OpenCV is an open source computer vision and machine learning software library." I have used OpenCV in personal projects, my Computer Vision class, my independent study, with robotics, and my thesis. I understand many of the underlying algorithms that are used for the built in functions, and thus understand from a deeper level how and when to implement them. 
"CUDA is a parallel computing platform and programming model invented by NVIDIA." I have come to understand CUDA at a deeper level through my thesis research. I not only understand the basics such (i.e. taking a serial program and making it parallel), but I also understand in depth the performance effects imposed by the hardware. 
I have been using Python since my freshman year of college. I learned it on my own, then again in my introduction computer science class. Some of my early projects included a chat-bot that was trained using only quotes from the movie Airplane. Unfortunately, I have no idea where the code resides as this was before I knew how to use Github. I also built a program that would automatically search items on Bing to get me "reward" points. I have written scripts to notify when new items containing certain keywords are posted to Craigslist. I wrote a website scraper to build a database of all the products on the Home Depot website. I wrote a scripting program to generate and run IDL code automatically for monthly reports at LASP. I have refactored PyQT GUIs for spacecraft telemetry decoding. I have written telemtry analysis programs. I have used Python whenever possible as I believe it is a great skill to have. It's free, it's supported, and it's easy, and it's powerful. Everyone should know Python well. 
I have used C for many computer science classes as well as my independent study, computer vision class, and my thesis. I am also familiar with Make/CMake and Visual Studio. When I need performance, I goto C/C++ as opposed to Python because of the control that it gives me over the programs. 
I have been using Matlab since freshman year of college. I would say that I am proficient with it. I have used it for numerical computation, linear algebra, engineering analysis, controls, and more. I am able to design a controller using the command line or Simulink. I am confident with generating plots for any style of report. 
I think that I am weird with my affinity for databases. It is incredibly satisfying for me to run a script then to execute a SQL query to get loads of data. I have used mainly SQL relational databases to store telemetry, science experiment results, Home Depot products scraped from the web, website data, and more. I have self educated myself with database design and am interested in storing large amounts of data quickly. 
I was born in Denver and moved after a few years to the small town of North Muskegon, Michigan. There, I attended North Muskegon Public Schools from kindergarten to 12th grade. I graduated at the top of my class with an unweighted GPA of 4.0 and many AP credit and community college credits from Muskegon Community College. 
When I turned 15, I got a job at Ruth Ann's Ice Cream making $4.25 per hour (before taxes...). At this job I did just about everything. I served delicious desserts,I cleaned tables. I washed windows. I dismantled, cleaned, and reassembled soft-serve machines. I did accounting at the end of the day to make sure that what was in the drawer matched receipts. I handled angry customers. Up to doing the purchasing and scheduling, I eseentially did everything necessary to run that business. I worked here until I had nothing else to learn, then moved on to other things. 
Midway through highschool, I also got a job at Whippi-Dip Ice Cream. One of my friends had partnered with the new owner and invited me to help as I knew the ins and outs of the ice cream business. I did this when I had spare time during the busy seasons. 
I have completed all the required coursework for a Bachelor's of Science degree in the Mechanical Engineering program. I have also completed all the courses required for a minor in Computer Science (CSCI). I am currently taking courses towards my Master's of Science in Mechanical Engineering. 
At a hackathon in 2017, I worked on a project to track specific colors using OpenCV. The end goal was to track a known pattern of colors to derive the localization of the camera using transformations of the centers of the colored blobs. I ran out of time and did not finish the localization part, but the tracking is pretty cool! Check it out on my Github! 
My thesis professor came across a mind bender in his daughter's classroom. On their wall, they had a square grid of 100 squares, each labeled with a unique number from 1 to 100. The question then became, on average, how many sticks need to be drawn to get a pizza party. Probably possible to do analytically (although I haven't figured out the math yet), the time commitment isn't worth it so he challenged me to solve it using a Monte Carlo simulation. I first wrote the simulation in Matlab, then translated it to C, and finally turned it into a CUDA application. In case you're wondering, the average is 72. Let me know if you can do it analytically... Check it out on my Github! 
Since I was about 10, I was running a lawn care business with one of my best friends. We would push the mowers from house to house until we turned 16 and were able to buy a trailer. After that purchase, we spent weekends from dawn to dusk mowing lawns. With age came wisdom, and we began to market ourselves as "inexpensive student help." Everybody loves to help out some dedicated, and the professional quality lawn care didn't hurt. 
By farm my favorite high school job-the Scenic Sky Alpaca Farm. I spent summers working here as a farmhand. I cleaned up after the animals, mowed pastures, mended fences, landscaped, and any other odd job that may have arisen. I would even work shifts when I came home from college on breaks. Unfortunately, the farm has since closed. 
I am a graduate student pursuing a concurrent Bachelor's and Master's degree in Mechanical Engineering at the the University of Colorado Boulder. Minoring in Computer Science, I have found that my passions lie more in the software side of engineering. Because of this, I began to focus my efforts on topics such as robotics, controls, and software engineering. Using knowledge gained from Mechanical Engineering courses in conjunction with skills learned in the computer science department, I am able to solve complex problems that involve both physical systems and complex software. 

 I was hired on as a Command Controller at the LASP in May of 2016. The first three months consisted of a training program to certify myself and eight others to be able to work on console with multiple different NASA spacecraft. By the end of the summer, I was one of few students who had the privelage to command these spacecraft. 

 Shortly after certifying, I was added to multiple spacecraft subsystems. These included the Attitude Determination and Control Subsystem on QuikSCAT, the Electrical Power Distribution Subsystem on SORCE and AIM, SORCE SIM and TIM instruments, and others. On all these subsystem teams, I performed unique tasks to help benefit the spacecraft as a whole. Below are short blurbs about some of the projects I worked on early at my time at LASP. 

 Nearing the end of my first year at LASP, I began to dabble with web projects. Eventually, I was added to the mission operations student web team. On this team, I created multiple tools to help benefit the entire flight operations team. This helped me gain experience in HTML, PHP, JavaScript, and SQL. I also learned that I enjoy full stack web development. Some examples of my projects are listed below. Unfortunately due to ITAR restrictions, I can't post the full extent of my work. 

 After my two year obligation with LASP, I applied to be a graduate research assistant to continue my work at LASP while continuing with my schooling. This application included a presentation depicting some of the work I did at LASP, which I had to give to all the flight directors, my supervisor, and the department director. After my application and presentation, I was appointed to the position of Graduate Lead for the QuikSCAT Spacecraft. 
When I became lead of the SORCE SIM subsystem, I found that the script that calculates and stores science experiment success statistics was incredibly slow (on the order of multiple hours for retrieving data for a single month). I took it upon myself to rewrite the code to not only work faster, but also smarter. Using IDL (LASP standard, not my first choice...), I implemented a system that evaluates experiment success by extracting scheduled activities and comparing with telemetry data. Doing this, I was able to determine if, when, and why a certain experiment failed. This data was then stored in a relational SQLite database for fast retrieval in the future. This updated code took a process that took hours per month and brought it down to just a few minutes. 
On QuikSCAT, there was a frequent problem that would occur with the reaction wheels. Occasionally, there would be a "jag" (a.k.a. torque drag) that would occur on one of the four wheels. The analysis started with the hypothesis that the frequency of the jags were temperature dependent, however I proved this to be false. Although the results were underwhelming, I created a new tool for telemetry analysis. Using IDL Widgets, something that was not really done at LASP before, I created a tool to look for correlation between telemetry points. Using a 2D binning technique, I was able to construct a heat map that showed not only any correlations between variables, but included a time intensity aspect using a rainbow coloring scheme. For me, this plot allowed me to quickly see if torque increases were temporary or persistent for long periods of time. Fun fact, the idea for this tool came from a common 2D histogram technique used in computer vision! 
When I joined the AIM Power subsystem, I was taught how to make lunar shadow predictions. These are made whenever there is a solar eclipse that could affect the spacecraft as we do not want to have a situation where the spacecraft undervoltages and is kicked into a safemode (espically on AIM since bitlock was non-existant and recovery would be near impossible). At a high level, the process consists of obtaining a Solar Intensity Report from STK and feeding it into some custom code that would scale existing solar array current based on the solar intensity as generated by STK. Using this information, we could calculate how much the battery would discharge due to insufficient energy and use this knowledge to provide recommendations to the flight director on how effects could be mitigated. When learning this process, the common theme seemed to be "this usually doesn't work." The code never seemed to run to completion and hours were wasted every time a lunar shadow approached. This time waste didn't make sense to me. So instead of spending hours debugging poorly documented code, I took it upon myself to rewrite the code to elminate time waste and improve the results. I created a GUI in IDL that had minimal inputs and output valuable plots. I was also able to model attitude mode behavior in the predictions to produce the most accurate results possible. To quote the lead of the subsystem, "This tool is magical." 
SORCE is an incredibly complex spacecraft, as discussed in this paper by my colleagues. Every orbit, all power draws that are not necessary to survival (and sometimes even those that are vital) are turned off at Earth eclipse entry. Once the spacecraft comes back into the sun, it must completely reconfigure itself and prepare to take science! This means there are multiple levels of automation. Relative time sequences can be loaded from the ground to spacecraft RAM that can be executed from the ground automation, absolute timed sequneces, on-board telemetry monitors, or other relative time sequneces. That is just one example of the complexity of the automation. So tracking something down like the source of a charge rate change can be challenging. I created a tool that shows what code calls what and where the calls originate. It allows operators to easily follow the flow of a signal or back out the origin of a response. Plus, the graph looks cool! It was done using VisJS in conjunction with custom PHP to allow users who are unfamiliar with web development to easily update nodes and edges. In the image below, each node is action. The actions are connected with directional edges. The actions are color coded by their origination. Zooming in with the scroll wheel allows users to quickly view information about the actions. 
The LASP Proc (short for Procedure) Reader was the brainchild of a student before me. He implemented it for two missions, hard coding much of the logic to be mission specific. I took his idea and gave it a makeover. The tool has many purposes. First, it provides syntax highlighting for CSTOL (Colorado System Test Operational Language, used for commanding LASP's spacecraft). Second, it allows users to easily follow the procedures. Procedures have many calls to other procedures (like calling a function from a function), and my tool allows the user to jump to the procedure that is called. It also allows a user to see an outline of the entire procedure in a navigation pane. This is useful for procedures, such as the Kepler Quarterly procedure, that are thousands of lines long. A user can easily jump to a specific section from anywhere in the procedure. The program also allows users to follow "GOTO" statements that redirect procedure flow to other labels in the file. With PHP and JS, I was able to provide these features for all of our missions, automatically. 
One of the big selling points of LASP as mission operators is that we thoroughly check telemetry for all of our missions daily. This allows us to catch large anomalies before they happen. In order to do this, there must be a log of who has checked what subsystems' telemetry. This was traditionally done using Python CGI and plain HTML. This worked great...in 2001. Now, we all have smart phones and plain HTML looks, well, plain. As a project to learn about Bootstrap, I revamped the plain HTML log and added some features. I created a grid that showed which telemetry was checked and which wasn't. I also created features that allow users to sort by checked status or mission to quickly determine if telemetry still needed checking. On top of it all, I added some fun animations when the cards were sorted. A basic project, but it got me excited about web development. 
As the Graduate Lead of QuikSCAT, I played a large role in the decommissioning of the 19 year old spacecraft. I was able to attend all meetings discussing decommissioning plans between Ball Aerospace, LASP, JPL, CARA, NEN, and more. I took in depth notes to keep meetings productive and provided knowledge of the spacecraft and operations concept when needed. Using my in depth understanding of the decommissioning plan, I was able to manage both student employees and professionals in the decommissioning process. For example, I was able to train both student and professional controllers on the contingency operations that may have needed to be performed and also taught flight controllers about the planning process for the succession of burns that occurred to lower QuikSCAT's orbit. 
One of my main duties during the actual decommissioning period was to provide ground stations with updated orbit information as quickly as possible. In order to passivate the spacecraft, we had to expend all the fuel to remove the pressure from the propulsion system and decrease the energy of the orbit as much as possible (QuikSCAT was built before the NASA regulation that any spacecraft put into orbit must be able to come out of orbit). To do this, we generated the concept of burn "clusters." A burn cluster consisted of three burns, each separated by one orbit (burning at perigee each time would lower the perigee such that the spacecraft would have more atmospheric drag and would thus reenter sooner). We did this a total of three times over the course of about two weeks, a very involved process. One large concern when burning to lower an orbit is that the ground stations must know when they should expect the spacecraft to arrive at the edge of their mask. We can of course predict this by assessing thruster efficiency and inputting the change of energy in the orbit into a tool like STK, but many assumptions must be made to do this and it showed to contain quite a bit of error. I was tasked with collecting real-time orbit information between burns (i.e. at a half orbit contact where the time bias wasn't too large for the station to acquire) and turning this into a future schedule for the ground stations. I did this by propegating (with HPOP propagator) the orbit based on point solution generated by QuikSCAT's onboard attitude determination algorithm. I then took this information to generate TLEs and then translated them to IIRVs in the format specified by the ground stations which were then sent over SFTP. This was just one of many tasks performed to help passivate the spacecraft. Not to mention, I had the privilege of sending the last command ever to the spacecraft! 
Another one of my tasks as a graduate student was to help with the ground segment of the CSIM cubesat mission. This was (and still is) a very involved mission that had a lot of work that needed to be done in a short amount of time. Starting in August 2018 for a November 2018 launch, myself and a couple other students had to learn the ins and outs of the mission in order to begin development on the ground station. We read the ICD for the Blue Canyon XB1 bus from cover to cover multiple times. We spent as much time as possible connected to the flight instrument through hardline to learn all the idiosyncrasies and bugs. We developed commissioning procedures, weekly operations concepts, and contingency plans. As a low budget mission, student support for ops was key (because it's cheap), so we made nearly all the decisions related to the ground (and many for the flight) segment of the operations. 
I was specifically in charge of the ground software. Internal to LASP, we have a lightweight command and control software that can be adapted for different missions. One of my first places of focus was configuring this software to work with our mission. I quickly became an expert with the software and was able to quickly troubleshoot any bugs. 
Interfacing with the spacecraft through this realtime command software was great, but an operations team also needs (very much so) to be able to analyze historic data. In order to do this, I had to quickly learn about space communication protocols such as CCSDS and AX.25. I then built a program that can take in raw, binary data from the flight unit, find and interpret the packets within the data, then store it for future retrieval. But in order to do this, I had to be able to interface with existing tools available at LASP. This meant that I had to abandon concepts that I was familiar with (such as SQL and flat JSON files) and adopt tools such as NetCDF. I successfully built a data pipeline that flowed data from the spacecraft, through the ground antenna, and finally to a file that was hosted on a server that could be accessed by a multitude of different plotting and analysis tools. 
Another important task that I had with this project was refactoring a beacon decoder, originally written for the MinXSS spacecraft. This tool allows amateur HAM radio operators to track the spacecraft and collect beacons from our radio, then transfer data back to the team. Although we can get back orbit data, this allows us to see that our spacecraft is healthy even when we don't have visibility. 
The CSIM project has been a stressful one, but one that made me realize that I like the fast paced environment of cubesats and the freedom for creativity. It has been one of my favorite projects to work on at LASP. 

 The Univeristy of Colorado Boulder's Mechanical Engineering Department hosts an incredible senior design program that has evolved over the years into something great. The department partners with industry leaders to provide teams with both the funding, resources, and support needed to develop a great product. 

 Early in the program, teams are formed by the professors based on skills and personality. The teams then meet to decide which projects they want to pursue. In a frenzy, the teams develop proposals for the companies as to why their team would be the best team for the project. Proposals are sent out, and the companies choose the one that they think fits their project the best. Teams then immediately get to work. We followed a strict systems engineering process. Teams started with a specs and planning report and presentation that was due shortly after receiving the project. This was presented to the client and the scope of the projects were negotiated. The teams then worked towards PDR, selecting designs and providing presentations for the client to communicate design intent and start to provide a schedule for the rest of the project. Finally, towards the end of the semester, CDR was completed. Teams presented high quality presentations to the clients with full designs and a complete schedule for going forward. For my team at least, no stone was left unturn. Along with the CDR, teams also had to undergo manufacturing reviews with the machinists and professors as well as test reviews. 

 The second semester of senior design began before the semester began. Over winter break, we were in the machine shop starting to create parts. Our philosophy was to frontload the semester so that we could deal with the problems as they arose with less stress due to the time constraint. This turned out to be a good way to attack it. Even though we were busy non-stop, we were able to deliver a functioning product to our client. 

 The project that our team tackled was titled (by the client) the "Unique Sequence Pin Extractor." It took me about a week to figure out what this meant. At a high level, my team created a device that would serve as a barrier between devices on the "Internet of Things" and the internet. An easy example is a self driving car. Imagine someone was able to hack into the steering system. This person could then cause havoc. Our device was designed to prevent brute force attacks on devices connected to the internet. If a password is entered correctly, the user is granted access. If the password is not correct, the device physically locks out the user. This is done by translating the input password into revolutions of gears. If the user gets the password correct, holes in the three concentric gears align and a laser is shown through all three gears, illuminating a phototransistor that then gives access to the device. If the user puts in the wrong password, the gears turn to a certain position and the holes in the gears then are not concentric. When the laser is shown, the phototransistor does not become illuminated. A custom logic circuit then supplies a large amount of current through a fuse and blows it, rendering the device useless. The user then cannot try to get into the device again until a technician replaces the fuse. 

 On this project, I served three primary roles. I was the CAD Engineer, Manufacturing Engineer, and Electrical Engineer. Below are some quick summaries of some of the components of the project that I led. 

 As CAD Engineer, it was my responsibility to develop a revision control methodology that would keep the design process simple. Coming from the a background of operations where revision control is key, I knew the importance of maintaining a tight revision control practice. The approach I took in doing this was to develop a software that would keep the documentation and revision process consistent. Using Google Sheets, I developed scripts that allowed users to easily register parts, make revisions, and link assemblies to different parts. I decided to use this approach instead of GrabCAD as my experience with GrabCAD in the past proved to be too complicated. With my method, we easily tracked what files lived where, what revision they were, and who the last person was to edit it. To accompany my custom software, I also wrote a comprehensive revision control document that communicated how I hoped that the revision control would be done. 

 Second semester was a frenzy to get as much machined as quickly as possible. A large issue that arises with the machine shop is that it gets extremely busy as the year moves forward. My goal was to get as many parts machined as quickly as possible so that we could minimize our time waiting for machines to be open. In order to do this, I had to schedule around people's class schedules, machine shop hours, and stock availability (we had a large quantity of items on back-order). I created an ambitious Gantt Chart, and somehow we stayed ahead of it. Because it was a team of six students, we rarely would have overlap when machining. Therefore I recognized that it would be difficult to commuincate what was done and what the next steps were. We made use of Slack, but it's not always a reliable way to commuincate detailed information about physical parts. To combat this, I developed a paper system. As parts were created, they were put into specific places in our locker and each got a status sheet that allowed us to detail what was done, what needed to be done, how much time was spent on it, etc. With this system, somebody could walk into the shop, grab the correct part, and know exactly what needed to be done next. With the paper taped directly to the parts, we were able to avoid confusion. 

 As the CAD engineer, one of my main jobs was ensuring the quality and manufacturability of drawings. In this specific project, tolerance stackup was a large concern. The project consisted of three sets of gears that were required to be in precise mesh. Keeping track of tolerances and their effects on the performance of the product required organization and attention to detail. Using my knowledge in drawing creation, I was able to fine tune tolerances to create a product that functioned as expected without having to scrap many parts. 

 One of the major components of this project was what we coined as the "Logic Circuit." The logic circuit was what controlled whether or not the user could gain access to the device. It had to be able to control an output based on different inputs. For example, if there was a signal from the phototransistor being lit by the laser, and there was a signal from the laser actually being fired, the logic circuit was to output a high signal to, in our case, extract a solenoid. In order to do this, I had to design a circuit using multiple logic gates to create the desired output. I simulated the circuit using National Instrument's Multisim program. Once I was happy with the performance of the simulation, I began to construct the circuit on a breadboard and iterated until I was happy with the performance of the prototype. Finally, the most difficult part, I had to design a PCB that was small enough to fit size constraint imposed by our client. In order to do this, I laid out the design using Eagle and made many iterations of the design until I got a design that worked. The final design worked as intended and I gained A LOT of knowledge out of the process. 

 When I first started on the robotics team in 2015, I joined the mechanical team. On this team, I used SOLIDWORKS to design the actuation system for our mining tool. I also spent multiple all nighters building and testing, building and testing. Our school's first year at the NASA Robotic Mining Competition did not go quite as well as we would have liked. Unfortunately, the software was not to where it needed to be and we were unable to communicate with the robot come competition time. 

 Going into my second year on the team, I once again was on the mechanical team helping to design critical components of the robot. This year however, trouble came just before leaving for competition. With about a month to spare and final exams on the horizion, our software team (really just one guy) took off, leaving behind no software. With very few options, I stepped up to the plate to try to figure something out. I spent hours and hours trying to learn ROS in time to get a functioning robot. With help from other teams on campus, I was able to wrap my head around how ROS works and write functioning software to achieve teleoperations on the robot. And the hours of frustrating work paid off when we managed to come in second place at the mining competition in Cape Canaveral! 

 The following year I accepted the role as software team lead. I managed the team as best I could, and we built some software that could have "theoretically" driven the robot autonomously. However, we were never able to test as the robot was not finished until just hours before packing up and leaving for competition. Unfortunately, belt system that was developed for the drivetrain could not achieve enough tension to keep the rubber belt from slipping on the cogs. In conjunction with the long wheel base and skid steering, we were not able to turn the robot. Fortunate for us, we were placed in the arena in such a way that we would have never needed to turn. We decided to perform the competition using teleoperations (because the autonomy was never tested enough to be confident with it). Everything was working great, until we dug our auger too deep into the regolith and got ourselves stuck, due once again to a belt slipping on the part to remove the tool from the regolith. We eventually ran our motors too hard in desperation to get unstuck and caught the robot on fire. Not the end we had hoped for. 

 Now, in my fourth year on the team, I have taken more of a mentor approach. As someone who has failed in this competition so many times, I understand what it takes to be successful. For example, I have been coaching the current software lead on how he can incorporate his team early and often. One approach to do this, build a test platform that anybody can test on. We will see how the team performs come May. Stay tuned... 

 As the QuikSCAT Graduate lead, I had many responsiblities to keep the mission running smoothly. These included scheduling meetings, managing subsystem teams, ensuring quality of reports, and more. I also had to perform tasks such as collision avoidance burn planning in the event that we got warning of a possible conjunction. In this position, I learned to become more organized and to delegate. 

 A major part of my schooling going into senior year became embedded computing. This led me into beginning to fiddle with the NVIDIA Jetson TX2, a GPU embedded on a single board computer. My computer vision professor, Dr. Shalom Ruben, asked me if I wanted to do an independent study with the TX2. After a semester of that, I then decided to pursue a thesis using GPU computing. 

 In the second semester of my senior year, I was approached by my computer vision professor, Dr. Shalom Ruben, to see if I wanted to do a independent study with him. He proposed a project where I would use the NVIDIA Jetson TX2 to do some sort of accelerated computer vision project. I thought this sounded like a riot so I accepted. Soon enough, I learned that simply running code on a device with a GPU is not enough to take advantage of the GPU. I began to learn about CUDA in depth and kept track of my pieces of code along the way on github. I learned about basic CUDA (blocks, threads, etc) and also began to dabble in memory optimizations. Dr. Ruben had the foresight that I needed to learn about the system before I could implement any truely fast computer vision project. Thus, I abandoned any large project and wrote lots of little pieces of code showing the ability of the TX2. 

 After my independent study with Dr. Ruben, we decided to take on a Master's thesis. I personally decided to do the thesis since LASP was going to be sponsoring me through graduate school. Currently in progress, I am investigating in depth the performance of different GPUs as well as the effects of multiple different optimization techniques on those GPUs. My end goal is to be able to accelerate live computer vision to the point where I can implement a biological cell tracking software that can label and track parent cells as they split into new cells. Eventually, I would like to implement deep learning to try to find any visual features that can determine if the cells are resistant to antibiotics before the drugs are introduced to the culture. 

 This class focused on preparing engineering students for the different programming languages they may encounter in the engineering field. We learned Matlab, C/C++, and VBA in Excel. Turns out, VBA in Excel is an incredibly useful skill to have as it can easily automate many tasks performed in Microsoft Office. I've automated analysis, data manipulation, presentation creation, etc using VBA! 

 This course taught me about how to use SOLIDWORKS, how to create manufacturable engineering drawings, and how to use the different machines in a machine shop. Notable projects in this class included designing and fabricating a "slot car" and modeling an existing product with three or more parts in SOLIDWORKS. I chose to do a longboard which taught me (probably more) than I wanted to learn about creating organic surfaces and performing complex mates. Unfortunately, those files have gone missing :( 

 This was a computer science class that taught about the different data structures, their pros and cons, and algorithms to help build them. Some concepts covered included linked lists, trees (of many varieties), arrays, etc. 

 Thermo I was your basic thermo class. Thermo II, however, was one of the more enlightening classes that I took at CU. This class mostly focused on the different power cycles, but most of our projects included designing some sort of system to meet requirements. For example, we had to design a cogeneration power system to replace the existing power system at a "tomato soup" plant, seen below. 

 The main project in this class was to build a "drill powered vehicle." I worked on a team of 6 over the semester to design, fabricate, and race our vehicle. I was the CAD engineer on the project and was responsible for drawings, renders, analysis, and more. We decided to build a tricycle type vehicle with a low center of gravity that was front wheel drive. We used a fork, wheel, and head tube of a child's bike then fabricated the rest of the frame ourselves. We ended up coming in second place after all was said and done (although the team that won may have bent the rules slightly ¯\_(ツ)_/¯ ) 

 Computer Systems was all about the low level functionality of computers. We learned optimization methods (for CPUs) such as loop unrolling, coalesced memory accesses etc. We also learned how to read and decipher assembly code. We also looked at basic security considerations such as code injection. All the concepts were driven home by the use of labs. 

 This class taught about many different manufacturing methods as well as manufacturing management strategies. We once again got a lot of time in the machine shop to help us understand the importance of good engineering drawing practices. The main project in this class was to create a "bike wheel light" that was waterproof, had a PCB that caused two LEDs to alternate, and a way to attach it to the wheel. At the end of the semester, each design was voted on, and my design won (see below). I created a box with an acrylic window to see all the electronics that was bonded to a 3D printed enclosure. I then had an access point for the electronics that was closed using screws that went into inset metal threaded inserts. I then sealed the whole thing with an o-ring. 

 Computer Vision (as taught in the Mechanical Engineering department) focused on the algorithms behind image processing. We learned about blurring techniques, edge detection algorithms (i.e. sobel, canny, etc), histograms, and more. We then implemented our knowledge on a course project. I started to do a soduku solver in which you take a picture of the board and then the computer solves it, but I got stuck at the machine learning portion of recognizing the numbers that were already present on the board. I then transitioned to a project in which I tracked specific shapes of a given number of sides. Not as exciting, but still was fun. 

 Data analysis talked about ways to retrieve data, then how to analyze it. We covered different types of sensors, DAQs, aliasing, clipping, etc. We then also talked about basic analysis such as fitting, statistical analysis, and more. The final project for this class was to devise an experiment in which data was collected then analyized. Our project looked at how quickly CO2 is secreted from a beverage as a function of container type and temperature. You can read about it here. 

 System Dynamics came in three parts. First, we learned about modeling complex systems using idealized elements. We then looked at how to look at these models in the Laplace domain and how to simulate their responses to given inputs using techniques such as transfer functions and convolution. Then we took this information to characterize the performance of given systems and assess if they meet requirements. We then spent time looking at the frequency domain analysis of systems, such as bode plots, fourier, etc. Finally, we spent time talking about control. Specifically about how to analyize the performance of different controllers. Techniques included root-locus and simulation. 

 Software development was a CSCI class that looked into high level concepts for software projects. Topics included HTML, CSS, Javascript, NodeJS, PHP, SQL, continuous integration, SAAS, PAAS, and more. The final project for this course was to build a website that included a database with at least three tables. I took the lead on the backend and integration for this project, creating features such as user login, forums, and some other simple features. 

 Data mining looks at the data pipeline. This class taught about data warehouses, frequent pattern analysis, clustering, classification, and other data analysis type methods. The final project for this course was to develop a data mining program. My team looked at the Yelp Academic dataset with hopes to extract features that will be able to tell if a business will be successful within its first three months of operation. 

 Feedback Control is a mechanical engineering graduate course that looks at different types of control. We spent time modeling systems then applying controllers to the system. We assessed systems in depth using root-locus, the frequency domain, Routh Horwitz criterion, simulation, and more. 
Every year, RedBull Energy puts on an event at Copper Mountain called SlopeSoakers. They hold a competition at CU Boulder in which they invite five teams to compete to design the course for the year. I have now done this two years in a row and have attended the event as a VIP both times! Loads of fun, lots of Redbull. 
Q: What in the heck is going on here? 
A: This is a graph of my skills, hobbies, experience, etc. It was made with vis.js. The nodes and edges show how the different aspects of my life connect. 
Q: Ok great, so what do I do? 
A: Try clicking my face! Most of the nodes have some information behind them. When you click on one, a modal will pop up and you can read about that specific node! 
Q: How do I navigate the page? 
A: There are lots of ways! I recommend using a mouse, but that's just personal preference. Here is some help on how to navigate:
